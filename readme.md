###Sentiment analysis example for the Brookhaven National Laboratory Postdoctoral application

The purpose of this example is to demonstrate my ability to collect, work with, clean, and classify a 
set of text documents related to a sentiment analysis problem in which the idea is to find the polarty
of text documents based on the lexical-syntactical structure of documents. 

This is one of my first attempts to obtained the sentiment attached to peer-review comments related to 
text documents in a data repository like Dspace (where there are text collections and communities).

Example features:

* All the programming files (.py) were implemented in Python 2.7
* The dataset used are part of a Spanish collection of tweets from TASS 2018 http://www.sepln.org/workshops/tass/
* The required Python packages to run the programs are the following:

	* Numpy (classification) http://www.numpy.org/
	* scikit-learn (classification) http://scikit-learn.org/stable/
	* NLTK (NLP techniques) https://www.nltk.org/
	* CLips pattern (NLP techniques) https://www.clips.uantwerpen.be/pattern

There are five folders that show the different steps used to clean, pre-process, represent and classify a set of 
text documents from some known samples:

	1. ParsingXMLFiles
	2. CleaningTxtFiles
	3. FeatureSet
	4. VectorRepresentation
	5. TrainingTesting
 
###Dspace work

Additionally to the python examples, an ontology (OntologyExample.owl file) created in protégé https://protege.stanford.edu/ 
is presented as an example of the kind of things in which I’m involve as a postdoctoral researcher.

It is important to notice that the ontology concepts and definitions are in Spanish, considering that the main 
purpose of this taxonomy is to modelate the relationships of text documents in a university scope where there 
are thesis, articles, etc.
